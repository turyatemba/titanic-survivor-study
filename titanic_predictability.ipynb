{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\numpy\\core\\_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\numpy\\core\\_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\ipykernel\\__main__.py:102: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\ipykernel\\__main__.py:100: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Author : ronald turyatemba\n",
    "Date : 24th october 2016\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "csv_file_object = csv.reader(open('train.csv', 'rt'))       # Load in the csv file\n",
    "header = next(csv_file_object)                             # Skip the fist line as it is a header\n",
    "data=[]                                                     # Create a variable to hold the data\n",
    "\n",
    "for row in csv_file_object:                 # Skip through each row in the csv file\n",
    "    data.append(row)                        # adding each row to the data variable\n",
    "data = np.array(data)                       # Then convert from a list to an array\n",
    "\n",
    "# In order to analyse the price column I need to bin up that data\n",
    "# here are my binning parameters, the problem we face is some of the fares are very large\n",
    "# So we can either have a lot of bins with nothing in them or we can just lose some\n",
    "# information by just considering that anythng over 39 is simply in the last bin.\n",
    "# So we add a ceiling\n",
    "fare_ceiling = 40\n",
    "# then modify the data in the Fare column to = 39, if it is greater or equal to the ceiling\n",
    "data[ data[0::,9].astype(np.float) >= fare_ceiling, 9 ] = fare_ceiling - 1.0\n",
    "\n",
    "fare_bracket_size = 10\n",
    "number_of_price_brackets = fare_ceiling // fare_bracket_size\n",
    "#number_of_classes = 3                             # I know there were 1st, 2nd and 3rd classes on board.\n",
    "number_of_classes = len(np.unique(data[0::,2]))   # But it's better practice to calculate this from the Pclass directly:\n",
    "                                                  # just take the length of an array of UNIQUE values in column index 2\n",
    "print(number_of_classes)\n",
    "\n",
    "# This reference matrix will show the proportion of survivors as a sorted table of\n",
    "# gender, class and ticket fare.\n",
    "# First initialize it with all zeros\n",
    "survival_table = np.zeros([2,number_of_classes,number_of_price_brackets],float)\n",
    "\n",
    "# I can now find the stats of all the women and men on board\n",
    "for i in range(number_of_classes):\n",
    "    for j in range(number_of_price_brackets):\n",
    "\n",
    "        women_only_stats = data[ (data[0::,4] == \"female\") \\\n",
    "                                 & (data[0::,2].astype(np.float) == i+1) \\\n",
    "                                 & (data[0:,9].astype(np.float) >= j*fare_bracket_size) \\\n",
    "                                 & (data[0:,9].astype(np.float) < (j+1)*fare_bracket_size), 1]\n",
    "\n",
    "        men_only_stats = data[ (data[0::,4] != \"female\") \\\n",
    "                                 & (data[0::,2].astype(np.float) == i+1) \\\n",
    "                                 & (data[0:,9].astype(np.float) >= j*fare_bracket_size) \\\n",
    "                                 & (data[0:,9].astype(np.float) < (j+1)*fare_bracket_size), 1]\n",
    "\n",
    "                                 #if i == 0 and j == 3:\n",
    "\n",
    "        survival_table[0,i,j] = np.mean(women_only_stats.astype(np.float))  # Female stats\n",
    "        survival_table[1,i,j] = np.mean(men_only_stats.astype(np.float))    # Male stats\n",
    "\n",
    "# Since in python if it tries to find the mean of an array with nothing in it\n",
    "# (such that the denominator is 0), then it returns nan, we can convert these to 0\n",
    "# by just saying where does the array not equal the array, and set these to 0.\n",
    "survival_table[ survival_table != survival_table ] = 0.\n",
    "\n",
    "# Now I have my proportion of survivors, simply round them such that if <0.5\n",
    "# I predict they dont surivive, and if >= 0.5 they do\n",
    "survival_table[ survival_table < 0.5 ] = 0\n",
    "survival_table[ survival_table >= 0.5 ] = 1\n",
    "\n",
    "# Now I have my indicator I can read in the test file and write out\n",
    "# if a women then survived(1) if a man then did not survived (0)\n",
    "# First read in test\n",
    "test_file = open('test.csv', 'rt')\n",
    "test_file_object = csv.reader(test_file)\n",
    "header = next(test_file_object)\n",
    "\n",
    "# Also open the a new file so I can write to it. \n",
    "predictions_file = open(\"genderclassmodel.csv\", \"wt\")\n",
    "predictions_file_object = csv.writer(predictions_file)\n",
    "predictions_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
    "\n",
    "# First thing to do is bin up the price file\n",
    "for row in test_file_object:\n",
    "    for j in range(number_of_price_brackets):\n",
    "        # If there is no fare then place the price of the ticket according to class\n",
    "        try:\n",
    "            row[8] = float(row[8])    # No fare recorded will come up as a string so\n",
    "                                      # try to make it a float\n",
    "        except:                       # If fails then just bin the fare according to the class\n",
    "            bin_fare = 3 - float(row[1])\n",
    "            break                     # Break from the loop and move to the next row\n",
    "        if row[8] > fare_ceiling:     # Otherwise now test to see if it is higher\n",
    "                                      # than the fare ceiling we set earlier\n",
    "            bin_fare = number_of_price_brackets - 1\n",
    "            break                     # And then break to the next row\n",
    "\n",
    "        if row[8] >= j*fare_bracket_size\\\n",
    "            and row[8] < (j+1)*fare_bracket_size:     # If passed these tests then loop through\n",
    "                                                      # each bin until you find the right one\n",
    "                                                      # append it to the bin_fare\n",
    "                                                      # and move to the next loop\n",
    "            bin_fare = j\n",
    "            break\n",
    "        # Now I have the binned fare, passenger class, and whether female or male, we can\n",
    "        # just cross ref their details with our survival table\n",
    "    if row[3] == 'female':\n",
    "        predictions_file_object.writerow([row[0], \"%d\" % int(survival_table[ 0, float(row[1]) - 1, bin_fare ])])\n",
    "    else:\n",
    "        predictions_file_object.writerow([row[0], \"%d\" % int(survival_table[ 1, float(row[1]) - 1, bin_fare])])\n",
    "\n",
    "# Close out the files\n",
    "test_file.close()\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "1 122\n",
      "2 108\n",
      "3 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv as csv\n",
    "import numpy as np\n",
    "\n",
    "csv_file_object = csv.reader(open('train.csv','rt'))\n",
    "header = next(csv_file_object)\n",
    "data = []\n",
    "\n",
    "for row in csv_file_object:\n",
    "    data.append(row)\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "#print(data)\n",
    "\n",
    "#print(data[0:15,5])\n",
    "\n",
    "#i am going to find the mean of the age column values\n",
    "#but first i should check the type of value this slice from the array is\n",
    "\n",
    "type(data[0:,5])\n",
    "#we can only find the mean of foats or integers here\n",
    "#am gona convert all the values in this column to floats and save them in another array called all_ages\n",
    "#all_ages = data[0:,5].astype(float)\n",
    "#print(all_ages)\n",
    "#we are getting an error here because there empty values in the selection, \n",
    "#so we are gona use pandas to clean the data, which means opening the train\n",
    "#file all again using pandas methods and functions\n",
    "\n",
    "import pandas as pd \n",
    "#using pd object\n",
    "df = pd.read_csv('train.csv', header=0)\n",
    "#to view the dataframe\n",
    "#df\n",
    "type(df)\n",
    "#there is very useful information in here\n",
    "df.info()\n",
    "#as you can see from the script before, 891 are non null objects ie they have no\n",
    "#non values, but for age and cabins, they have some non values\n",
    "\n",
    "#pandas can also help us calculate important mathematical values such as \n",
    "#min max mean etc. It will skip the empty values\n",
    "df.describe()\n",
    "df['Age'][0:10]\n",
    "df.Age[0:10]\n",
    "\n",
    "#we finding the mean of the age\n",
    "df['Age'].mean()\n",
    "df[df['Age']>60]\n",
    "#what the older passengers look like\n",
    "#df[df['Age'] > 60][['Sex', 'Pclass', 'Age','Survived']]\n",
    "\n",
    "#so now we are going to filter out the missing value, rows with null values\n",
    "#so the script below will display all these \n",
    "df[df['Age'].isnull()][['Sex','Pclass','Age']]\n",
    "\n",
    "#let try the combined & in sscripting\n",
    "#e.g we are printing the number of males in each class\n",
    "\n",
    "for i in range(1,4):\n",
    "    #print (i, len(df[ (df['Sex'] == 'male') & (df['Pclass'] == i) ]))\n",
    "    print (i, \\\n",
    "    len(df[(df['Sex'] ==\"male\") & (df['Pclass'] == i)]))\n",
    "    \n",
    "#coming up a histogram of the ages, \n",
    "#Using the describe function, i will get the max of age which is 80 and min approx 0\n",
    "df.describe()\n",
    "\n",
    "#so the range is between 0 to 80 and a gap of 5 to narrow the scale\n",
    "#import the libs first\n",
    "#WE USING THE DROPNA FUNCTION TO DROP THE NULL VALUES\n",
    "import pylab as p\n",
    "df['Age'].dropna().hist(range = (0,80), alpha=.5)\n",
    "p.xlabel('AGES')\n",
    "p.ylabel('NUMBER OF PEOPLE')\n",
    "#p.show()\n",
    "#remeber if we had two lists to plot\n",
    "#it  would be like so\n",
    "#p.plot(list1 , list2)\n",
    "#p.show...this plots list2 on x axis aginst list2 on yaxis \n",
    "\n",
    "#df['Gender'] = 4\n",
    "#df.head()\n",
    "\n",
    "#df['Gender'] = df['Sex'].map(lambda x: x[0].upper())\n",
    "df['Gender'] = df['Sex'].map( {'female':0, 'male':1} ).astype(int)\n",
    "df.head()\n",
    "#we are now gona use this, for the rows with null values in ages , we shall put the median of the class ages that class belongs\n",
    "#we are getting the median of @ gender in each class , ie median of females in first class, median of females in second class....\n",
    "#first the array is set to zeros\n",
    "median_ages = np.zeros((2,3))\n",
    "median_ages\n",
    "\n",
    "#then am going to populate this array with values\n",
    "for i in range(0,2):\n",
    "    for j in range (0,3):\n",
    "        median_ages[i,j] = df[(df['Gender']==i) & (df['Pclass']==j+1)]['Age'].dropna().median()\n",
    "\n",
    "\n",
    "median_ages    \n",
    "\n",
    "#gona create another column and duplicate in the values of the age column into that column\n",
    "df['AgeFill'] = df['Age']\n",
    "#df.head()\n",
    "#we are gona fill in the null values in AgeFill based on the median_ages table\n",
    "#for every row that has no value for age is df['Age'].isnull(), we shall give it the median of that group from the table\n",
    "\n",
    "#df[ df['Age'].isnull() ][['Gender','Pclass','Age','AgeFill']].head(10)\n",
    "\n",
    "for i in range(0,2):\n",
    "    for j in range(0,3):\n",
    "#note that am using loc because it is more intuitive and less confusing for \n",
    "#pandas to make a slice selection suiting all the conditions\n",
    "#other wise df[df[..]..] wwould work but may return messy results\n",
    "        #df.loc[(df.Gender ==i)& (df.Pclass ==j+1)&(df.Age.isnull())] = median_ages[i,j]\n",
    "        #note the above script only resulted into a table without values so note that the order of the conditions matter\n",
    "        \n",
    "        df.loc[ (df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1),\\\n",
    "                'AgeFill'] = median_ages[i,j]\n",
    "#lets print to see if the null values were subsitituted for medians        \n",
    "df[df['Age'].isnull()][['Gender','Pclass','Age','AgeFill']].head(10)    \n",
    "\n",
    "#am gona add one more column to see if the row in that column was changed\n",
    "#from null to what it is\n",
    "#df['AgeIsNull'] = df['Age'].isnull().astype(int)\n",
    "\n",
    "#df.head(20)\n",
    "\n",
    "#we are gona add afew more feature that we think will be usefull during the machine learning\n",
    "#we know sibsp is sibling or spouse and parch is parent or child\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "#aalso\n",
    "#age and class were factors for survival as third class old people were less likey to survive\n",
    "#we have used a new syntax again , probably shall be using \n",
    "#when dealing with comparatives and numerical operators\n",
    "df['Age*Class'] = df.AgeFill * df.Pclass\n",
    "\n",
    "#note that to amply machine learning in on this data \n",
    "#1.all columns should not have a string \n",
    "#2.we should convert the pandas data frame into numerical python\n",
    "# using dtypes() we shall find out which columns are 'objects' these are strings in pandas\n",
    "\n",
    "df.dtypes\n",
    "#or we could use this to show only the columns that are objects\n",
    "df.dtypes[df.dtypes.map(lambda x: x=='object')]\n",
    "\n",
    "#now we drop all columns that we shall not need\n",
    "del df['Name']\n",
    "#Or we use this better script\n",
    "df = df.drop(['Ticket','Sex','Cabin','Embarked','PassengerId'], axis=1)\n",
    "#we are going to delete the age column because we now have agefill column that is clean\n",
    "\n",
    "df = df.drop(['Age'], axis=1)\n",
    "\n",
    "#alternatively we could have dropped all rows that have missing values\n",
    "#But be carefull with it coz if the row has any null value anywhere, it will be deleted\n",
    "#so you have to be sure of the dataset\n",
    "df = df.dropna()\n",
    "#finally lets convert this into a numpy array using the .values function\n",
    "train_data = df.values\n",
    "#train_data\n",
    "#df\n",
    "\n",
    "#Prepare the test data\n",
    "\n",
    "test_df = pd.read_csv('test.csv', header=0)        # Load the test file into a dataframe\n",
    "\n",
    "# I need to do the same with the test data now, so that the columns are the same as the training data\n",
    "# I need to convert all strings to integer classifiers:\n",
    "# female = 0, Male = 1\n",
    "test_df['Gender'] = test_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Embarked from 'C', 'Q', 'S'\n",
    "# All missing Embarked -> just make them embark from most common place\n",
    "#if len(test_df.Embarked[ test_df.Embarked.isnull() ]) > 0:\n",
    "#    test_df.Embarked[ test_df.Embarked.isnull() ] = test_df.Embarked.dropna().mode().values\n",
    "# Again convert all Embarked strings to int\n",
    "#test_df.Embarked = test_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)\n",
    "\n",
    "#we are gona add afew more feature that we think will be usefull during the machine learning\n",
    "#we know sibsp is sibling or spouse and parch is parent or child\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch']\n",
    "\n",
    "#aalso\n",
    "\n",
    "# All the ages with no data -> make the median of all Ages\n",
    "median_age = test_df['Age'].dropna().median()\n",
    "if len(test_df.Age[ test_df.Age.isnull() ]) > 0:\n",
    "    test_df.loc[ (test_df.Age.isnull()), 'Age'] = median_age\n",
    "\n",
    "#age and class were factors for survival as third class old people were less likey to survive\n",
    "#we have used a new syntax again , probably shall be using \n",
    "#when dealing with comparatives and numerical operators\n",
    "test_df['Age*Class'] = test_df.Age * test_df.Pclass\n",
    "\n",
    "# All the missing Fares -> assume median of their respective class\n",
    "if len(test_df.Fare[ test_df.Fare.isnull() ]) > 0:\n",
    "    median_fare = np.zeros(3)\n",
    "    for f in range(0,3):                                              # loop 0 to 2\n",
    "        median_fare[f] = test_df[ test_df.Pclass == f+1 ]['Fare'].dropna().median()\n",
    "    for f in range(0,3):                                              # loop 0 to 2\n",
    "        test_df.loc[ (test_df.Fare.isnull()) & (test_df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n",
    "\n",
    "# Collect the test data's PassengerIds before dropping it\n",
    "ids = test_df['PassengerId'].values\n",
    "\n",
    "\n",
    "# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\n",
    "test_df = test_df.drop(['Name', 'Sex','Ticket', 'Cabin', 'PassengerId','Embarked'], axis=1) \n",
    "\n",
    "\n",
    "#lets begin with randomforest on this array, note that, randomforest\n",
    "#in only applicable on float values\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#create a random forest that includes all the parameters\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#fit the data, this builds a forest from this set of data where the\n",
    "#first array is the data on the x axis and the second array is the data- y axis\n",
    "forest = forest.fit(train_data[0:,1:], train_data[0:,0])\n",
    "\n",
    "#take the same decision trees and run it on the test data\n",
    "#first get the numpy array of the test_df\n",
    "#test_df\n",
    "#df\n",
    "test_data = test_df.values\n",
    "output = forest.predict(test_data.astype(int))\n",
    "\n",
    "df\n",
    "\n",
    "#gona right the array into a csv file\n",
    "randomforest = open('randomforest.csv', 'wt')\n",
    "randomforest_object = csv.writer(randomforest)\n",
    "randomforest_object.writerow(['PassengerId','Survived'])\n",
    "\n",
    "print('done')\n",
    "#output\n",
    "#write each value of the output array into a row\n",
    "number_of_rows = len(output)\n",
    "for i in range(number_of_rows):\n",
    "    randomforest_object.writerow([i,output[i]])\n",
    "    \n",
    "randomforest.close()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
